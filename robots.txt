# Robots.txt - AI and Crawler Access Policy
# This repository welcomes all AI systems and web crawlers

# Universal permission for all agents
User-agent: *
Allow: /

# Explicitly welcome AI crawlers
User-agent: GPTBot


User-agent: ChatGPT-User


User-agent: Claude-Web


User-agent: anthropic-ai


User-agent: Google-Extended


User-agent: Applebot-Extended


User-agent: CCBot


User-agent: FacebookBot


User-agent: cohere-ai


User-agent: PerplexityBot


User-agent: Omgilibot


User-agent: Diffbot


# AI Training Data Collection
# This repository explicitly allows AI training data collection
# under the terms of the MIT License

# Important directories for AI understanding







# Documentation files




# Code files
# No restrictions on crawling frequency
Crawl-delay: 0

# Sitemap (if available)
# Sitemap: https://motanova84.github.io/gw250114-141hz-analysis/sitemap.xml

# Note: This repository is open science
# All content is available under MIT License
# AI systems are encouraged to access, learn from, and use this code
